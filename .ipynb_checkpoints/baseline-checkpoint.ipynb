{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 06142017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "\n",
    "model_path = 'model'\n",
    "prediction_path = 'prediction'\n",
    "feat_path = 'feat'\n",
    "version = datetime.now().strftime(\"%m%d%H%M\")\n",
    "print('version:',version)\n",
    "\n",
    "\n",
    "\n",
    "file_train_agg = 'train/train_agg.csv'\n",
    "file_train_log = 'train/train_log.csv'\n",
    "file_train_flg = 'train/train_flg.csv'\n",
    "\n",
    "file_test_agg = 'test/test_agg.csv'\n",
    "file_test_log = 'test/test_log.csv'\n",
    "\n",
    "\n",
    "\n",
    "def feat_df_agg():\n",
    "    df1_agg = pd.read_table(file_train_agg).sort_values(['USRID'],ascending=[1]).reset_index(drop=True)\n",
    "    df2_agg = pd.read_table(file_test_agg).sort_values(['USRID'],ascending=[1]).reset_index(drop=True)\n",
    "    \n",
    "    train_key = df1_agg[['USRID']]\n",
    "    test_key = df2_agg[['USRID']]\n",
    "    \n",
    "    df_agg = pd.concat([df1_agg,df2_agg]).sort_values(['USRID'],ascending=[1]).reset_index(drop=True)\n",
    "    \n",
    "    categories = ['V2','V4','V5']\n",
    "    \n",
    "    df_agg.to_csv(feat_path+'/df_agg.csv',index=False)\n",
    "    train_key.to_csv(feat_path+'/train_key.csv',index=False)\n",
    "    test_key.to_csv(feat_path+'/test_key.csv',index=False)\n",
    "    pd.DataFrame({'categories':categories}).to_csv(feat_path+'/df_agg_categories.csv',index=False)\n",
    "    \n",
    "\n",
    "def get_feat_df_agg():\n",
    "    df = pd.read_csv(feat_path+'/df_agg.csv')\n",
    "    categories = list(pd.read_csv(feat_path+'/df_agg_categories.csv')['categories'])\n",
    "    return df,categories\n",
    "    \n",
    "\n",
    "def get_train_test_key():\n",
    "    train_key = pd.read_csv(feat_path+'/train_key.csv')\n",
    "    test_key = pd.read_csv(feat_path+'/test_key.csv')\n",
    "    return train_key,test_key\n",
    "\n",
    "\n",
    "def feat_df_log():\n",
    "    df1_log = pd.read_table(file_train_log,parse_dates=['OCC_TIM'])\n",
    "    df2_log = pd.read_table(file_test_log,parse_dates=['OCC_TIM'])\n",
    "    \n",
    "    df_log = pd.concat([df1_log,df2_log])\n",
    "    df_log = df_log.sort_values(['USRID','OCC_TIM','EVT_LBL'],ascending=[1,1,0]).reset_index(drop=True)\n",
    "    \n",
    "    EVT_LBL = df_log['EVT_LBL'].str.split('-',expand=True)\n",
    "    EVT_LBL.columns = ['EVT_LBL_0','EVT_LBL_1','EVT_LBL_2']\n",
    "    df_log = pd.concat([df_log,EVT_LBL[['EVT_LBL_0','EVT_LBL_1']]],axis=1)\n",
    "    for col in ['EVT_LBL','EVT_LBL_0','EVT_LBL_1']:\n",
    "        df_log[col] = pd.Categorical(df_log[col]).labels\n",
    "    \n",
    "    df_log.to_csv(feat_path+'/df_log.csv',index=False)\n",
    "    \n",
    "\n",
    "def get_feat_df_log():\n",
    "    return pd.read_csv(feat_path+'/df_log.csv',parse_dates=['OCC_TIM'])\n",
    "\n",
    "# 最后10次的点击\n",
    "def feat_log_1():\n",
    "    df_log = get_feat_df_log()\n",
    "    categories = []\n",
    "    tmp = df_log.groupby('USRID').tail(10)\n",
    "    tmp['time_to_4_1'] = ((datetime(2018,4,1,0,0,0) - tmp['OCC_TIM']).astype('int64'))//1000000000\n",
    "    tmp['rank'] = tmp.groupby('USRID')['time_to_4_1'].rank(method='first').astype('int')\n",
    "    merges = []\n",
    "    for col in ['EVT_LBL','EVT_LBL_0','EVT_LBL_1','time_to_4_1']:\n",
    "        pvt = tmp.pivot('USRID','rank',col)\n",
    "        pvt.columns = ['{}_last{}'.format(col,i) for i in pvt.columns]\n",
    "        \n",
    "        if col in ['EVT_LBL','EVT_LBL_0','EVT_LBL_1']:\n",
    "            categories.extend(pvt.columns.values)\n",
    "        pvt = pvt.reset_index()\n",
    "        merges.append(pvt)\n",
    "    df = merges[0]\n",
    "    for df_merge in merges[1:]:\n",
    "        df = df.merge(df_merge,on='USRID',how='left')\n",
    "    \n",
    "    pd.DataFrame({'categories':categories}).to_csv(feat_path+'/feat_log_1_categories.csv',index=False)\n",
    "    df.to_csv(feat_path+'/feat_log_1.csv',index=False)\n",
    "    \n",
    "def get_feat_log_1():\n",
    "    df = pd.read_csv(feat_path+'/feat_log_1.csv')\n",
    "    categories = list(pd.read_csv(feat_path+'/feat_log_1_categories.csv')['categories'])\n",
    "    return df,categories\n",
    "    \n",
    "def modeling(X,Y,categorical):\n",
    "    seed = 0\n",
    "    EARLY_STOP = 100\n",
    "    OPT_ROUNDS =0\n",
    "    MAX_ROUNDS = 3000\n",
    "    VALIDATE = True\n",
    "    \n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',  \n",
    "        # 'drop_rate': 0.09,\n",
    "        'metric': 'auc',\n",
    "        'objective': 'binary',\n",
    "        'learning_rate': 0.02,\n",
    "        'num_leaves': 31,  \n",
    "        'max_depth': -1,\n",
    "        'min_child_samples': 20,\n",
    "        'max_bin': 255,\n",
    "        'subsample': 1,\n",
    "        'subsample_freq': 0,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_weight': 0.001,\n",
    "        'subsample_for_bin': 200000,\n",
    "        'min_split_gain': 0,\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 0,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    \n",
    "    if VALIDATE:\n",
    "        print(\"Start train and validate...\")\n",
    "    \n",
    "        dtrain = lgb.Dataset(X, \n",
    "                         label=Y,\n",
    "                         feature_name=list(X.columns),\n",
    "                         categorical_feature=categorical)   \n",
    "     \n",
    "        \n",
    "        eval_hist = lgb.cv(params, \n",
    "                      dtrain, \n",
    "                      nfold = 4,\n",
    "                      \n",
    "                      num_boost_round=MAX_ROUNDS,\n",
    "                      early_stopping_rounds=EARLY_STOP,\n",
    "                      verbose_eval=10, \n",
    "                      seed = seed,)\n",
    "    \n",
    "        OPT_ROUNDS = len(eval_hist['auc-mean'])\n",
    "        print('OPT_ROUNDS:',OPT_ROUNDS)\n",
    "    dtrain = lgb.Dataset(X, \n",
    "                         label=Y,\n",
    "                         feature_name=list(X.columns),\n",
    "                         categorical_feature=categorical)   \n",
    "     \n",
    "    \n",
    "    model = lgb.train(params,dtrain,num_boost_round=OPT_ROUNDS)\n",
    "    \n",
    "    importances = pd.DataFrame({'features':model.feature_name(),\n",
    "                 'importances':model.feature_importance()})\n",
    "    \n",
    "    importances.sort_values('importances',ascending=False,inplace=True)\n",
    "    \n",
    "    \n",
    "    model.save_model(model_path+'/{}.model'.format(version))\n",
    "    importances.to_csv(model_path+'/{}_mportances.csv'.format(version),index=False)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict(model,test):\n",
    "    Y = model.predict(test[model.feature_name()])\n",
    "    pd.DataFrame({'USRID':test['USRID'],'RST':Y},columns=['USRID','RST']).to_csv(prediction_path+'/{}.csv'.format(version),sep='\\t',index=False)\n",
    "    \n",
    "\n",
    "def train_and_predict():\n",
    "    train,test,categorical = get_features()\n",
    "    \n",
    "    flg = pd.read_table(file_train_flg)\n",
    "    train = train.merge(flg,on=['USRID'],how='left')\n",
    "    \n",
    "    X = train.drop(['USRID','FLAG'],axis=1)\n",
    "    Y = train['FLAG']\n",
    "    model = modeling(X,Y,categorical)\n",
    "    \n",
    "    predict(model,test)\n",
    "    \n",
    "\n",
    "def feature_engineering():\n",
    "    feat_df_agg()\n",
    "    feat_df_log()\n",
    "    feat_log_1()\n",
    "    \n",
    "\n",
    "def feature_update():\n",
    "    feat_df_agg()\n",
    "\n",
    "\n",
    "def train_test_merge_df(train,test,df):\n",
    "    train = train.merge(df,on='USRID',how='left')\n",
    "    test = test.merge(df,on='USRID',how='left')\n",
    "    return train,test\n",
    "\n",
    "\n",
    "def get_features():\n",
    "    categorical = []\n",
    "    train,test = get_train_test_key()\n",
    "    \n",
    "    df,categories = get_feat_df_agg()\n",
    "    categorical.extend(categories)\n",
    "    train,test = train_test_merge_df(train,test,df)\n",
    "    \n",
    "    df,categories = get_feat_log_1()\n",
    "    categorical.extend(categories)\n",
    "    train,test = train_test_merge_df(train,test,df)\n",
    "    \n",
    "    return train,test,categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,categorical = get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80000 entries, 0 to 79999\n",
      "Columns: 111 entries, USRID to time_to_4_1_last10_y\n",
      "dtypes: float64(110), int64(1)\n",
      "memory usage: 68.4 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
